<?xml version="1.0" encoding="UTF-8"?>
<gretl-functions>
<gretl-function-package name="CvDataSplitter" minver="2020a">
<author email="atecon@posteo.de">Artur Tarassow</author>
<version>0.2</version>
<date>2021-06-15</date>
<description>Compile cross-validation datasets</description>
<tags>C52</tags>
<help>
Package for generating datasets for cross-validation purposes.

Learning parameters of a prediction function is a major objective. In order
to avoid over-fitting, the model is trained on a different data sample 
(the 'training set') and evaluated out-of-sample on a so called 'test set'.
This approach is known as cross-validation (CV).

This package comprises different approaches of dividing the raw data set into
a training and test set, respectively, depending on the nature of the
underlying data.

An nice overview can be accessed here:
https://scikit-learn.org/stable/modules/cross_validation.html

The separated data sets are stored in array of matrices, which can be read-in
for the original model training and evaluation.

Written by: Artur Tarassow (atecon@posteo.de)

Github project page &amp; pull requests:
https://github.com/atecon/CvDataSplitter


Public Function:
================
CvDataSplitter()

Parameters:
===========
The user needs to pass some bundle 'b' in pointer form to the function
CvDataSplitter(), e.g. &lt;CvDataSplitter(&amp;b)&gt;, which includes at least:
(i) A list named 'X' with k series, or a matrix named 'X' with T rows
and k columns.
In case a matrix 'X' was passed, the user additionally needs to pass
(ii) a column vector named 'index' referring to the T observations (can
be easily generated via gretl by 'genr index').

Additionally, the user can optionally specify the following 2 parameters:
cv_type		-- string, Type of cross-validation (CV):
		(i) 'kfold' (default),
		(ii) 'loo' (Leave-One-Out)
		(iii) 'recwin' (recursive window for time-series (TS) data)
		(iv) 'rolwin' (rolling window using a fixed window-width
		for TS data)

n_folds		-- int, divide sample into n_folds of groups of equal
		size (can only be set for cv_type='kfold' (default 5);
		otherwise determined by the respective CV procedure)

win_size	-- int, (Initial) Window-width for moving-window related
		methods 'rolwin' and 'recwin' (default 25 pct. of total
		valid observations)

Returns:
=========
The function returns the following information to the bundle 'b':
X_train		-- array of 'n_folds' matrices, each matrix is of dimension
		T(i) by (1+k) (for i=1,2,...) holding the observation
		index in the 1st column and the training data for k
		variables across columns.
X_test		-- array of 'n_folds' matrices, each matrix is of dimension
		T(j) by (1+k) (j=1,2,...) holding the observation index in the
		1st column and the test data for k variables across columns.



## Changelog

### v0.2 (June 2021)
- Fix typos
- Catch error if number of folds exceeds number of observations.
- Minimum gretl version required is now 2020a

### v0.1 (March 2019)
- Initial version
</help>
<gretl-function name="CvDataSplitter" type="void">
 <params count="1">
  <param name="self" type="bundleref"/>
 </params>
<code>/*=======================*/
/* Main package function */
/*=======================*/
# Set up the bundle
#==================
bundle b = default_cv_opts()
self = self + b		    		# override defaults
# Initial checks
#===============
check_bundle(&amp;self)
# Drop missing
#==============
# TODO: think about how to handle NAs
#    smpl --no-missing y X
# Generate an observation index
#===============================
if !inbundle(self, &quot;index&quot;) &amp;&amp; (typeof(self.X)==7 || typeof(self.X)==2)
  genr index
  self.index = index		# index series for checking that values are related to the right unit
endif
# Call evaluation method
#=======================
if self.cv_type==&quot;kfold&quot; || self.cv_type==&quot;loo&quot;
  kfold(&amp;self)
elif self.cv_type==&quot;recwin&quot; || self.cv_type==&quot;rolwin&quot;
  timefold(&amp;self)
endif
# Clear some bundle elements
clear_bundle(&amp;self)
</code>
</gretl-function>
<gretl-function name="clear_bundle" type="void" private="1">
 <params count="1">
  <param name="self" type="bundleref"/>
 </params>
<code>/* Helper function for dropping some bundle elements
before returning */
delete self.X
delete self.index
if self.cv_type!=&quot;recwin&quot; || self.cv_type!=&quot;rolwin&quot;
  delete self.win_size
endif
if self.cv_type==&quot;recwin&quot;
  delete self.foldsize
endif
</code>
</gretl-function>
<gretl-function name="default_cv_opts" type="bundle" private="1">
<code># Set default values of the bundle
bundle self = null
string self.cv_type = &quot;kfold&quot;		# &quot;kfold&quot;, &quot;rep_kfold&quot;, &quot;loo&quot;, &quot;recwin&quot;, &quot;rolwin&quot;
scalar self.n_folds = 5				# divide sample into k groups of samples (default for kfold = 5)
scalar self.win_size = int(0.25*$nobs)	# for 'recwin'/'rolwin': initial window lenght
return self
</code>
</gretl-function>
<gretl-function name="check_bundle" type="void" private="1">
 <params count="1">
  <param name="self" type="bundleref"/>
 </params>
<code>/* Some initial checks for bundle completeness */
if !inbundle(self, &quot;X&quot;)
  funcerr &quot;Provide a list or matrix with data entitled 'X'.&quot;
endif
if typeof(self.X)==3		# if matrix
  if !inbundle(self, &quot;index&quot;)
    funcerr &quot;Provide a vector holding index observations values (via 'genr index') named 'index'.&quot;
  elif inbundle(self, &quot;index&quot;)
    if typeof(self.index)!=3
      funcerr &quot;Make sure your object 'index' is of type matrix (row vector).&quot;
    endif
  endif
endif
</code>
</gretl-function>
<gretl-function name="gen_xmatrices" type="void" private="1">
 <params count="1">
  <param name="self" type="bundleref"/>
 </params>
<code>/* Helper function for generating an
array for storing the output */
matrices self.X_train = array(self.n_folds)
matrices self.X_test = array(self.n_folds)
</code>
</gretl-function>
<gretl-function name="get_T" type="scalar" private="1">
 <params count="1">
  <param name="self" type="bundleref"/>
 </params>
<code>/* Helper function returning no. of observations */
return (typeof(self.X)==7) ? $nobs : rows(self.X)
</code>
</gretl-function>
<gretl-function name="kfold" type="void" private="1">
 <params count="1">
  <param name="self" type="bundleref"/>
 </params>
<code>/* Function for running kfold and loo
Splits data in train/test sets.
Split dataset into k consecutive folds (without shuffling).
Each fold can be used once as a validation while the k - 1 remaining
folds form the training set.
'loo' is a special case of 'kfold' with a single obs. left-out for each fold
See: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html
*/
# No. of folds
self.n_folds = (self.cv_type==&quot;loo&quot;) ? $nobs : self.n_folds
# Read-in frame
X = self.X
# Index
if typeof(X)==2 || typeof(X)==7
  series index = self.index
else
  matrix index  = self.index
endif
# Generate test/training arrays
gen_xmatrices(&amp;self)
# Length of each test sample
scalar T = get_T(&amp;self)
scalar self.foldsize = int(T/self.n_folds)			# length of test sample
scalar rest = T - self.n_folds*self.foldsize		# no. of remainder obs for last iteration
# Initial test set indices
scalar start = min(index)
scalar ende = start + self.foldsize - 1
# Start looping
loop i=1..self.n_folds -q
  # Test set
  if typeof(X)==7								# For list-based approach
    series active_set = 0					# don't drop: indicator for current sample
    smpl index&gt;=start &amp;&amp; index&lt;=ende --restrict
    active_set = 1							# don't drop
    self.X_test[i] = {index} ~ {X}
  else					# For matrix-based approach
    matrix active_set = (index.&gt;=start &amp;&amp; index.&lt;=ende)
    self.X_test[i] = selifr(index,active_set) ~ selifr(X,active_set)
  endif
  # Training set
  if typeof(X)==7			# For list-based approach
    smpl active_set==0 --restrict --replace
    self.X_train[i] = {index} ~ {X}
    smpl full
  else
    active_set = (active_set.=1) ? 0 : 1				# select training set
    self.X_train[i] = selifr(index,active_set) ~ selifr(X,active_set)
  endif
  # update start/ ende
  start += self.foldsize
  ende = start + self.foldsize-1
  ende = (i==self.n_folds) ? (ende+rest) : ende
endloop
</code>
</gretl-function>
<gretl-function name="timefold" type="void" private="1">
 <params count="1">
  <param name="self" type="bundleref"/>
 </params>
<code>/* Function for either rolling or recursive window splits when working
with time-series data.
See: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.TimeSeriesSplit.html#sklearn.model_selection.TimeSeriesSplit
*/
# Read-in frame
X = self.X
# Index
if typeof(X)==2 || typeof(X)==7
  series index = self.index
else
  matrix index  = self.index
endif
# Length of each test sample
scalar T = get_T(&amp;self)
scalar self.foldsize = self.win_size			# length of (initial) test sample
#    scalar rest = T-self.n_folds*self.foldsize	# no. of remainder obs for last iteration
# Generate test/training arrays
scalar self.n_folds = T - self.foldsize		# T-1 training sets can be compiled
errorif(self.n_folds &lt; 0, sprintf(&quot;Parameter 'foldsize' (=%d) cannot exceed number of observations 'T' (=%d).&quot;, self.foldsize, T))
flush
gen_xmatrices(&amp;self)
# Initial test set indices
scalar start = min(index)
scalar ende = start + self.foldsize - 1
# Start looping
loop i=1..self.n_folds -q
  #        printf &quot;\nStart=%d \t Ende=%d\n&quot;, start, ende
  # Training set
  if typeof(X)==7								# For list-based approach
    series active_set = 0					# don't drop: indicator for current sample
    smpl index&gt;=start &amp;&amp; index&lt;=ende --restrict --replace
    active_set = 1						# don't drop
    self.X_train[i] = {index} ~ {X}
  else					# For matrix-based approach
    matrix active_set = (index.&gt;=start &amp;&amp; index.&lt;=ende)
    self.X_train[i] = selifr(index,active_set) ~ selifr(X,active_set)
  endif
  # Test set
  if typeof(X)==7			# For list-based approach
    smpl index&gt;ende --restrict --replace
    self.X_test[i] = {index} ~ {X}
    smpl full
  else
    active_set = (index.&gt;ende)
    self.X_test[i] = selifr(index,active_set) ~ selifr(X,active_set)
  endif
  # update start/ ende
  start = (self.cv_type==&quot;rolwin&quot;) ? (start+1) : start
  ende++
endloop
</code>
</gretl-function>
<sample-script>
clear 
set verbose off

include CvDataSplitter.gfn --force

# EXAMPLE
#=========
open australia.gdt -q

# Define variables
#------------------
series LHS = ldiff(PAU)
list RHS = const LHS(-1 to -2) #ldiff(PUS) IUS(-1 to -2)  IAU(-1 to -2)
list L = LHS RHS

# Drop missing values
#---------------------
smpl --no-missing L

# Select method:
#---------------
scalar use_matrices = 0			# 0: pass a list, 1: pass a matrix

# Initialize empty bundle
#-------------------------
bundle b = null

if use_matrices
    matrix X = {L}
    genr index					# when using matrices, you must pass a index vector
    matrix mindex = {index}
    b.X = X
    b.index = mindex    
else
    list b.X = L
endif

# Select cross-validation type (optional)
#-----------------------------------------
# b.win_size = 6				# optional: window-width for 'recwin'/'rolwin'
# b.n_folds = 3			# optional: divide sample into n_folds of groups for 'kfold'
# b.cv_type = &quot;rolwin&quot;			# 'kfold' (default), 'loo', 'recwin', 'rolwin'


# Pass bundle 'b' in pointer form + run
#---------------------------------------
CvDataSplitter(&amp;b)
print b


# Print training + test datasets stored as matrices
#--------------------------------------------------
eval b.X_train[3]		# grab array of X for some training set
eval b.X_test[3]		# grab array of X for some test set
</sample-script>
</gretl-function-package>
</gretl-functions>
